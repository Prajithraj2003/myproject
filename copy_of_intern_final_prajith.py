# -*- coding: utf-8 -*-
"""Copy of intern final Prajith.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z_gklaimGwp5BfC98OkOI5nBLC8zfzFq
"""

!pip install pyspark

from pyspark.sql.session import SparkSession
sess=SparkSession.builder.getOrCreate()
train=sess.read.csv('/content/whr2023 (1).csv',header=True)
train.count()
train.printSchema()

#Analyzing overall country happiness score
from pyspark.sql.functions import avg
print("Overall Happiness score: " + str(train.select(avg("Happinessscore")).collect()[0][0]))

#Country with max happiness
msal=train.agg({'Happinessscore': 'max'}).collect()[0][0]
country=train.filter(train['Happinessscore']==float(msal)).collect()[0][0]
print("Country with max happiness: ",country)
#Country with min happiness (sadness)
msal=train.agg({'Happinessscore': 'min'}).collect()[0][0]
country=train.filter(train['Happinessscore']==float(msal)).collect()[0][0]
print("Country with min happiness: ",country)

df=train.toPandas()

df

import matplotlib.pyplot as plt

df['Happinessscore']

ndf=df['Happinessscore'].astype(float)
ndf.plot(y='Happinessscore', figsize=(9,6))

ndf=df[['Happinessscore','upperwhisker','lowerwhisker']].astype(float)
ndf.plot.line(y=['Happinessscore','upperwhisker','lowerwhisker'], figsize=(10,6))

ndf=df[['Happinessscore','upperwhisker','lowerwhisker']].astype(float)
ndf[['Happinessscore','lowerwhisker']].plot(kind='hist', bins=25, alpha=0.6, figsize=(9,6))

ndf.plot(kind='box', figsize=(9,6))

ndf.plot(kind='area', figsize=(9,6))

from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
df = spark.read.csv('/content/whr2023 (1).csv',
                    header = True,
                    inferSchema = True)
df.printSchema()

import pandas as pd
pd.DataFrame(df.take(5), columns=df.columns)

df.count(), df.dropDuplicates().count(), df.dropna().count()

from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler
from pyspark.ml import Pipeline

categoricalColumns = ['Countryname','isoalpha','Regionalindicator']

stages = []
cols = df.columns
for categoricalCol in categoricalColumns:
  stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')
  encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + "classVec"])
  stages += [stringIndexer, encoder]

numericCols = ['Happinessscore','upperwhisker','lowerwhisker','Healthylifeexpectancy']
assemblerInputs = [c + "classVec" for c in categoricalColumns] + numericCols
assembler = VectorAssembler(inputCols=assemblerInputs, outputCol="features")
stages += [assembler]
pipeline = Pipeline(stages = stages)
pipelineModel = pipeline.fit(df)
df = pipelineModel.transform(df)

selectedCols = ['upperwhisker', 'features']
df = df.select(selectedCols)
df.printSchema()

df.show()

train, test = df.randomSplit([0.7, 0.3], seed = 2018)
print("Training Dataset Count: " + str(train.count()))
print("Test Dataset Count: " + str(test.count()))

from pyspark.ml.regression import LinearRegression
lr = LinearRegression(featuresCol = 'features', labelCol='upperwhisker', maxIter=10, regParam=0.3, elasticNetParam=0.8)
lr_model = lr.fit(train)

# Perform predictions
lr_predictions = lr_model.transform(test)
lr_predictions.select("prediction","upperwhisker","features").show(5)

# Evaluate prediction accuracy (R2)
from pyspark.ml.evaluation import RegressionEvaluator
lr_evaluator = RegressionEvaluator(predictionCol="prediction", \
                 labelCol="upperwhisker",metricName="r2")
print(lr_evaluator.evaluate(lr_predictions))

from pyspark.ml.regression import DecisionTreeRegressor
dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'upperwhisker')
dt_model = dt.fit(train)

dt_predictions = dt_model.transform(test)
dt_predictions.show(5)

dt_evaluator = RegressionEvaluator(
    labelCol="upperwhisker", predictionCol="prediction", metricName="r2")
r2 = dt_evaluator.evaluate(dt_predictions)
print(r2)

from pyspark.ml.regression import GBTRegressor
gbt = GBTRegressor(featuresCol = 'features', labelCol = 'upperwhisker', maxIter=50)
gbt_model = gbt.fit(train)

#Perform predictions
gbt_predictions = gbt_model.transform(test)
gbt_predictions.select('prediction', 'upperwhisker', 'features').show(5)

gbt_evaluator = RegressionEvaluator(
    labelCol="upperwhisker", predictionCol="prediction", metricName="r2")
r2 = gbt_evaluator.evaluate(gbt_predictions)
print(r2)

from pyspark.sql.session import SparkSession
sess=SparkSession.builder.getOrCreate()
train=sess.read.csv('/content/whr2023 (1).csv',header=True)
train.count()
train.printSchema()

df=train.toPandas()

df

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression
from pyspark.ml.evaluation import RegressionEvaluator
import pandas as pd
import matplotlib.pyplot as plt

spark = SparkSession.builder \
    .appName("whr Analysis") \
    .getOrCreate()

df= spark.read.csv("/content/whr2023 (1).csv", header=True, inferSchema=True)

df.printSchema()

df.describe().show()

assembler = VectorAssembler(inputCols=["Happinessscore", "Healthylifeexpectancy"], outputCol="features", handleInvalid="skip")
df_ml = assembler.transform(df)

lr = LinearRegression(featuresCol='features', labelCol='Healthylifeexpectancy')

lr_model = lr.fit(df_ml)

evaluator = RegressionEvaluator(labelCol='Happinessscore', predictionCol='prediction', metricName='rmse')

rmse = evaluator.evaluate(lr_model.transform(df_ml))
print("Root Mean Squared Error (RMSE):", rmse)

pandas_df = df.toPandas()

plt.scatter(pandas_df['Healthylifeexpectancy'], pandas_df['Happinessscore'])
plt.xlabel('Healthylifeexpectancy')
plt.ylabel('Happinessscore')
plt.title('Happinessscore vs Healthylifeexpectancy')
plt.show()

import matplotlib.pyplot as plt
import pandas as pd

spark = SparkSession.builder.appName("World happinessAnalysis").getOrCreate()
data = spark.read.csv("/content/whr2023 (1).csv", header=True,
inferSchema=True)

train, test = df.randomSplit([0.7, 0.3], seed = 2018)
print("Training Dataset Count: " + str(train.count()))
print("Test Dataset Count: " + str(test.count()))

# Data to plot
labels = ['Happinessscore', 'Healthylifeexpectancy', 'Logged GDP per capita', 'Social support	']
sizes = [25, 30, 20, 25]  # Percentage distribution
colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']
explode = (0.1, 0, 0, 0)  # explode 1st slice

# Plotting the pie chart
plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)

plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data
df = pd.read_csv("/content/whr2023 (1).csv")

# Calculate the correlation matrix
corr = df[['Happinessscore', 'Healthylifeexpectancy', 'Logged GDP per capita', 'Social support']].corr()

# Create the heatmap
fig = plt.figure(figsize=(12, 8))
sns.heatmap(corr, cmap='Blues', linewidth=0.5, annot=True)

# Display the heatmap
plt.show()

plt.bar(pandas_df['Healthylifeexpectancy'], pandas_df['Happinessscore'])
plt.xlabel('Healthylifeexpectancy')
plt.ylabel('Happinessscore')
plt.title('Happinessscore vs Healthylifeexpectancy')
plt.show()

# Get the best happiness score and the corresponding country
best_happinessscore = df['Happinessscore'].max()
best_country = df.loc[df['Happinessscore'] == best_happinessscore, 'Countryname'].values[0]

print(f"Best Happiness Score: {best_happinessscore}")
print(f"Best Country: {best_country}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error

# Load the dataset
data = pd.read_csv("/content/whr2023 (1).csv")

# Select features and target variable
features = data[['Logged GDP per capita', 'Social support', 'Healthylifeexpectancy',
                 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']]
target = data['Happinessscore']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Initialize the decision tree regressor
model = DecisionTreeRegressor(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Function to find the happiest country based on input features
def predict_happiest_country(log_gdp, social_support, healthy_life_expectancy, freedom, generosity, corruption):
    # Create a DataFrame for the input features
    input_features = pd.DataFrame({
        'Logged GDP per capita': [log_gdp],
        'Social support': [social_support],
        'Healthylifeexpectancy': [healthy_life_expectancy],
        'Freedom to make life choices': [freedom],
        'Generosity': [generosity],
        'Perceptions of corruption': [corruption]
    })

    # Predict happiness score for the input features
    predicted_score = model.predict(input_features)[0]

    # Find the country with the closest predicted score
    data['PredictedHappinessScore'] = model.predict(features)
    closest_country_row = data.iloc[(data['PredictedHappinessScore'] - predicted_score).abs().argsort()[:1]]
    closest_country = closest_country_row['Countryname'].values[0]
    closest_country_features = closest_country_row[['Logged GDP per capita', 'Social support', 'Healthylifeexpectancy',
                                                    'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']].values[0]

    return closest_country, closest_country_features, predicted_score

# Example usage of the function
log_gdp = 9.0
social_support = 0.6
healthy_life_expectancy = 6.0
freedom = 0.7
generosity = 0.9
corruption = 0.2

happiest_country, happiest_country_features, predicted_score = predict_happiest_country(
    log_gdp, social_support, healthy_life_expectancy, freedom, generosity, corruption
)

print(f'Happiest Country: {happiest_country}')
print(f'Relevant Features: {happiest_country_features}')
print(f'Predicted Happiness Score: {predicted_score}')

